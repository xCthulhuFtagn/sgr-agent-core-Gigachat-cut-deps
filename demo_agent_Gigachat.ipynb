{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac38ba1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dotenv in ./.venv/lib/python3.12/site-packages (0.9.9)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.12/site-packages (2.32.5)\n",
      "Requirement already satisfied: langchain_community in ./.venv/lib/python3.12/site-packages (0.3.31)\n",
      "Requirement already satisfied: langchain_gigachat in ./.venv/lib/python3.12/site-packages (0.3.12)\n",
      "Requirement already satisfied: tavily in ./.venv/lib/python3.12/site-packages (1.1.0)\n",
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.13.1-cp310-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: python-dotenv in ./.venv/lib/python3.12/site-packages (from dotenv) (1.2.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests) (2.6.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests) (2025.11.12)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=0.3.78 in ./.venv/lib/python3.12/site-packages (from langchain_community) (0.3.80)\n",
      "Requirement already satisfied: langchain<2.0.0,>=0.3.27 in ./.venv/lib/python3.12/site-packages (from langchain_community) (0.3.27)\n",
      "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in ./.venv/lib/python3.12/site-packages (from langchain_community) (2.0.45)\n",
      "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in ./.venv/lib/python3.12/site-packages (from langchain_community) (6.0.3)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./.venv/lib/python3.12/site-packages (from langchain_community) (3.13.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in ./.venv/lib/python3.12/site-packages (from langchain_community) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in ./.venv/lib/python3.12/site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in ./.venv/lib/python3.12/site-packages (from langchain_community) (2.12.0)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in ./.venv/lib/python3.12/site-packages (from langchain_community) (0.4.59)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in ./.venv/lib/python3.12/site-packages (from langchain_community) (0.4.3)\n",
      "Requirement already satisfied: numpy>=1.26.2 in ./.venv/lib/python3.12/site-packages (from langchain_community) (2.3.5)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.22.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./.venv/lib/python3.12/site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain_community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in ./.venv/lib/python3.12/site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in ./.venv/lib/python3.12/site-packages (from langchain<2.0.0,>=0.3.27->langchain_community) (0.3.11)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in ./.venv/lib/python3.12/site-packages (from langchain<2.0.0,>=0.3.27->langchain_community) (2.12.5)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in ./.venv/lib/python3.12/site-packages (from langchain-core<2.0.0,>=0.3.78->langchain_community) (1.33)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in ./.venv/lib/python3.12/site-packages (from langchain-core<2.0.0,>=0.3.78->langchain_community) (4.15.0)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in ./.venv/lib/python3.12/site-packages (from langchain-core<2.0.0,>=0.3.78->langchain_community) (25.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./.venv/lib/python3.12/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=0.3.78->langchain_community) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./.venv/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in ./.venv/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (3.11.5)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in ./.venv/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in ./.venv/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (0.12.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in ./.venv/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (0.25.0)\n",
      "Requirement already satisfied: anyio in ./.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (4.12.0)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain_community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in ./.venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain_community) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in ./.venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain_community) (0.4.2)\n",
      "Requirement already satisfied: greenlet>=1 in ./.venv/lib/python3.12/site-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain_community) (3.3.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./.venv/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain_community) (1.1.0)\n",
      "Requirement already satisfied: gigachat<0.2.0,>=0.1.41.post1 in ./.venv/lib/python3.12/site-packages (from langchain_gigachat) (0.1.43)\n",
      "Requirement already satisfied: types-requests<3.0,>=2.32 in ./.venv/lib/python3.12/site-packages (from langchain_gigachat) (2.32.4.20250913)\n",
      "Downloading faiss_cpu-1.13.1-cp310-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (23.7 MB)\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.0/23.7 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:06\u001b[0m"
     ]
    }
   ],
   "source": [
    "# !pip install dotenv requests langchain_community langchain_gigachat tavily faiss-cpu\n",
    "\n",
    "# !pip install -e \".[dev]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d56662b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- GIGA CONFIG: {'base_url': 'https://gigachat.devices.sberbank.ru/api/v1', 'verify_ssl_certs': False, 'main_model': 'GigaChat', 'temperature': 0.0} ---\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import logging\n",
    "from dotenv import load_dotenv\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "_LOGGER = logging.getLogger(__name__)\n",
    "\n",
    "load_dotenv()\n",
    "_LOGGER.info(\"--- envs've been successfully loaded ---\")\n",
    "\n",
    "@dataclass\n",
    "class GigaSettings:\n",
    "    # --- –ü–ê–†–ê–ú–ï–¢–†–´ GIGACHAT API ---\n",
    "    base_url: str\n",
    "    verify_ssl_certs: bool=False\n",
    "    main_model: str=\"GigaChat\" # –ò–∑–º–µ–Ω–∏–ª –Ω–∞ Pro, —Ç–∞–∫ –∫–∞–∫ Max –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω\n",
    "    temperature: float=0.0\n",
    "\n",
    "# –û–ø—Ä–µ–¥–µ–ª—è–µ–º URL. –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—É–±–ª–∏—á–Ω—ã–π API, –∫–æ—Ç–æ—Ä—ã–π —Ä–∞–±–æ—Ç–∞–µ—Ç –≤–µ–∑–¥–µ.\n",
    "# –ï—Å–ª–∏ –Ω—É–∂–µ–Ω IFT –∫–æ–Ω—Ç—É—Ä, –∑–∞–¥–∞–π—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –æ–∫—Ä—É–∂–µ–Ω–∏—è GIGACHAT_API_URL\n",
    "_api_url = os.getenv(\"GIGACHAT_API_URL\", \"https://gigachat.devices.sberbank.ru/api/v1\")\n",
    "# –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ /v1 –µ—Å–ª–∏ –æ–Ω–æ —É–∂–µ –µ—Å—Ç—å –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è\n",
    "if not _api_url.endswith(\"/v1\") and \"/api\" not in _api_url:\n",
    "     _api_url = f\"{_api_url}/v1\"\n",
    "\n",
    "giga_settings = GigaSettings(\n",
    "    _api_url,\n",
    "    False\n",
    ")\n",
    "\n",
    "_LOGGER.info(f\"--- GIGA CONFIG: {asdict(giga_settings)} ---\")\n",
    "print(f\"--- GIGA CONFIG: {asdict(giga_settings)} ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1892e388-5f51-412f-96ca-328c1c16e326",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET https://gigachat.devices.sberbank.ru/api/v1/models \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "–î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏ GigaChat:\n",
      "- GigaChat\n",
      "- GigaChat-2\n",
      "- GigaChat-2-Max\n",
      "- GigaChat-2-Pro\n",
      "- GigaChat-Max\n",
      "- GigaChat-Max-preview\n",
      "- GigaChat-Plus\n",
      "- GigaChat-Pro\n",
      "- GigaChat-Pro-preview\n",
      "- GigaChat-preview\n",
      "- Embeddings\n",
      "- Embeddings-2\n",
      "- EmbeddingsGigaR\n",
      "- GigaEmbeddings-3B-2025-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://gigachat.devices.sberbank.ru/api/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Could not import faiss python package. Please install it with `pip install faiss-gpu` (for CUDA supported GPU) or `pip install faiss-cpu` (depending on Python version).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/DEV/sgr-agent-core-Gigachat-cut-deps/.venv/lib/python3.12/site-packages/langchain_community/vectorstores/faiss.py:56\u001b[39m, in \u001b[36mdependable_faiss_import\u001b[39m\u001b[34m(no_avx2)\u001b[39m\n\u001b[32m     55\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m         \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfaiss\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'faiss'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 117\u001b[39m\n\u001b[32m    115\u001b[39m text_splitter = RecursiveCharacterTextSplitter(chunk_size=\u001b[32m1000\u001b[39m, chunk_overlap=\u001b[32m200\u001b[39m)\n\u001b[32m    116\u001b[39m splits = text_splitter.split_documents(documents)\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m vectorstore = \u001b[43mFAISS\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_function\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m retriever = vectorstore.as_retriever(search_kwargs={\u001b[33m\"\u001b[39m\u001b[33mk\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m2\u001b[39m})\n\u001b[32m    121\u001b[39m \u001b[38;5;66;03m# --- 3. –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã ---\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/DEV/sgr-agent-core-Gigachat-cut-deps/.venv/lib/python3.12/site-packages/langchain_core/vectorstores/base.py:837\u001b[39m, in \u001b[36mVectorStore.from_documents\u001b[39m\u001b[34m(cls, documents, embedding, **kwargs)\u001b[39m\n\u001b[32m    834\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ids):\n\u001b[32m    835\u001b[39m         kwargs[\u001b[33m\"\u001b[39m\u001b[33mids\u001b[39m\u001b[33m\"\u001b[39m] = ids\n\u001b[32m--> \u001b[39m\u001b[32m837\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/DEV/sgr-agent-core-Gigachat-cut-deps/.venv/lib/python3.12/site-packages/langchain_community/vectorstores/faiss.py:1044\u001b[39m, in \u001b[36mFAISS.from_texts\u001b[39m\u001b[34m(cls, texts, embedding, metadatas, ids, **kwargs)\u001b[39m\n\u001b[32m   1025\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Construct FAISS wrapper from raw documents.\u001b[39;00m\n\u001b[32m   1026\u001b[39m \n\u001b[32m   1027\u001b[39m \u001b[33;03mThis is a user friendly interface that:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1041\u001b[39m \u001b[33;03m        faiss = FAISS.from_texts(texts, embeddings)\u001b[39;00m\n\u001b[32m   1042\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1043\u001b[39m embeddings = embedding.embed_documents(texts)\n\u001b[32m-> \u001b[39m\u001b[32m1044\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__from\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1045\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1046\u001b[39m \u001b[43m    \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1047\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1048\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1049\u001b[39m \u001b[43m    \u001b[49m\u001b[43mids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1050\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1051\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/DEV/sgr-agent-core-Gigachat-cut-deps/.venv/lib/python3.12/site-packages/langchain_community/vectorstores/faiss.py:996\u001b[39m, in \u001b[36mFAISS.__from\u001b[39m\u001b[34m(cls, texts, embeddings, embedding, metadatas, ids, normalize_L2, distance_strategy, **kwargs)\u001b[39m\n\u001b[32m    984\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m    985\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__from\u001b[39m(\n\u001b[32m    986\u001b[39m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    994\u001b[39m     **kwargs: Any,\n\u001b[32m    995\u001b[39m ) -> FAISS:\n\u001b[32m--> \u001b[39m\u001b[32m996\u001b[39m     faiss = \u001b[43mdependable_faiss_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    997\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m distance_strategy == DistanceStrategy.MAX_INNER_PRODUCT:\n\u001b[32m    998\u001b[39m         index = faiss.IndexFlatIP(\u001b[38;5;28mlen\u001b[39m(embeddings[\u001b[32m0\u001b[39m]))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/DEV/sgr-agent-core-Gigachat-cut-deps/.venv/lib/python3.12/site-packages/langchain_community/vectorstores/faiss.py:58\u001b[39m, in \u001b[36mdependable_faiss_import\u001b[39m\u001b[34m(no_avx2)\u001b[39m\n\u001b[32m     56\u001b[39m         \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfaiss\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m     59\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCould not import faiss python package. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     60\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPlease install it with `pip install faiss-gpu` (for CUDA supported GPU) \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     61\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mor `pip install faiss-cpu` (depending on Python version).\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     62\u001b[39m     )\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m faiss\n",
      "\u001b[31mImportError\u001b[39m: Could not import faiss python package. Please install it with `pip install faiss-gpu` (for CUDA supported GPU) or `pip install faiss-cpu` (depending on Python version)."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import uuid\n",
    "import logging\n",
    "import requests\n",
    "import urllib3\n",
    "import httpx\n",
    "from dotenv import load_dotenv\n",
    "from typing import List, Optional, Dict, Any, ClassVar, Type\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Langchain imports\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_gigachat.embeddings.gigachat import GigaChatEmbeddings\n",
    "\n",
    "# Agent Core imports\n",
    "from sgr_deep_research.core.agent_definition import (\n",
    "    AgentConfig, \n",
    "    LLMConfig, \n",
    "    PromptsConfig, \n",
    "    ExecutionConfig\n",
    ")\n",
    "from sgr_deep_research.gigachat_compatability.agents.tool_calling_agent import ToolCallingAgent_functional as ToolCallingAgent\n",
    "from sgr_deep_research.gigachat_compatability.base_tool import BaseTool_functional\n",
    "from sgr_deep_research.gigachat_compatability.tools.clarification_tool import ClarificationTool_functional\n",
    "from sgr_deep_research.gigachat_compatability.tools.generate_plan_tool import GeneratePlanTool_functional\n",
    "from sgr_deep_research.gigachat_compatability.tools.adapt_plan_tool import AdaptPlanTool_functional\n",
    "from sgr_deep_research.gigachat_compatability.tools.reasoning_tool import ReasoningTool_functional\n",
    "from sgr_deep_research.gigachat_compatability.tools.final_answer_tool import FinalAnswerTool_functional\n",
    "from sgr_deep_research.gigachat_compatability.models import ResearchContextCounted as ResearchContext\n",
    "from openai import AsyncOpenAI\n",
    "\n",
    "# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö (.env)\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# --- 1. –ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–æ–∫–µ–Ω–∞ GigaChat ---\n",
    "def get_gigachat_token(auth_key: str, scope: str = \"GIGACHAT_API_PERS\") -> str:\n",
    "    \"\"\"–ü–æ–ª—É—á–∞–µ—Ç —Ç–æ–∫–µ–Ω –¥–æ—Å—Ç—É–ø–∞ GigaChat —Å –ø–æ–º–æ—â—å—é –∫–ª—é—á–∞ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏.\"\"\"\n",
    "    token_url = \"https://ngw.devices.sberbank.ru:9443/api/v2/oauth\"\n",
    "    \n",
    "    payload = {'scope': scope}\n",
    "    headers = {\n",
    "        'Content-Type': 'application/x-www-form-urlencoded',\n",
    "        'Accept': 'application/json',\n",
    "        'RqUID': str(uuid.uuid4()),\n",
    "        'Authorization': f'Basic {auth_key}'\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(token_url, headers=headers, data=payload, verify=False)\n",
    "        response.raise_for_status()\n",
    "        return response.json()['access_token']\n",
    "    except Exception as e:\n",
    "        print(f\"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ç–æ–∫–µ–Ω–∞: {e}\")\n",
    "        if 'response' in locals():\n",
    "             print(f\"–û—Ç–≤–µ—Ç —Å–µ—Ä–≤–µ—Ä–∞: {response.text}\")\n",
    "        raise\n",
    "\n",
    "# –ü–æ–ª—É—á–∞–µ–º –∫–ª—é—á –∏–∑ .env\n",
    "auth_key = os.getenv(\"GIGACHAT_CREDENTIALS\")\n",
    "if not auth_key:\n",
    "    raise ValueError(\"GIGACHAT_CREDENTIALS –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ .env! –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ–∞–π–ª .env\")\n",
    "\n",
    "# –ü–æ–ª—É—á–∞–µ–º –∞–∫—Ç—É–∞–ª—å–Ω—ã–π —Ç–æ–∫–µ–Ω\n",
    "ACCESS_TOKEN = get_gigachat_token(auth_key)\n",
    "# print(f\"–¢–æ–∫–µ–Ω —É—Å–ø–µ—à–Ω–æ –ø–æ–ª—É—á–µ–Ω: {ACCESS_TOKEN}\")\n",
    "\n",
    "from openai import OpenAI # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –∫–ª–∏–µ–Ω—Ç OpenAI\n",
    "import httpx # httpx –Ω—É–∂–µ–Ω –¥–ª—è http_client, –¥–∞–∂–µ –≤ —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–º —Ä–µ–∂–∏–º–µ\n",
    "\n",
    "def print_giga_models_sync():\n",
    "    client = OpenAI( # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –∫–ª–∏–µ–Ω—Ç\n",
    "        api_key=ACCESS_TOKEN,\n",
    "        base_url=giga_settings.base_url,\n",
    "        http_client=httpx.Client(verify=giga_settings.verify_ssl_certs) # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π httpx.Client\n",
    "    )\n",
    "    models = client.models.list() # –°–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –≤—ã–∑–æ–≤\n",
    "    print(\"\\n–î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏ GigaChat:\")\n",
    "    for model in models.data:\n",
    "        print(f\"- {model.id}\")\n",
    "\n",
    "print_giga_models_sync() \n",
    "\n",
    "# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è GigaChat (–ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º –Ω–∞–ª–∏—á–∏–µ giga_settings –∫–∞–∫ –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª–µ, –∏–ª–∏ –∑–∞–¥–∞–µ–º —Ç—É—Ç)\n",
    "class GigaSettings:\n",
    "    base_url = \"https://gigachat.devices.sberbank.ru/api/v1\"\n",
    "    verify_ssl_certs = False\n",
    "    main_model = \"GigaChat\"\n",
    "    temperature = 0.0\n",
    "\n",
    "giga_settings = GigaSettings()\n",
    "\n",
    "\n",
    "# --- 2. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ FAISS (–ö–∞—Ç–∞–ª–æ–≥ —Ç–æ–≤–∞—Ä–æ–≤ –∏ –ø—Ä–∞–≤–∏–ª–∞ –º–∞–≥–∞–∑–∏–Ω–∞) ---\n",
    "embedding_function = GigaChatEmbeddings(\n",
    "    base_url=giga_settings.base_url,\n",
    "    access_token=ACCESS_TOKEN,\n",
    "    verify_ssl_certs=giga_settings.verify_ssl_certs\n",
    ")\n",
    "\n",
    "documents = [\n",
    "    Document(page_content=\"–ö–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä '–ó–≤–µ–∑–¥–Ω—ã–π –∫—Ä–µ–π—Å–µ—Ä' —Å—Ç–æ–∏—Ç 5000 —Ä—É–±–ª–µ–π. –ü–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –¥–µ—Ç–µ–π –æ—Ç 10 –ª–µ—Ç.\", metadata={\"id\": \"prod1\"}),\n",
    "    Document(page_content=\"–ü–ª—é—à–µ–≤—ã–π –º–µ–¥–≤–µ–¥—å '–ú–∏—à—É—Ç–∫–∞' (50 —Å–º) —Å—Ç–æ–∏—Ç 1200 —Ä—É–±–ª–µ–π.\", metadata={\"id\": \"prod2\"}),\n",
    "    Document(page_content=\"–ù–∞—Å—Ç–æ–ª—å–Ω–∞—è –∏–≥—Ä–∞ '–ú–æ–Ω–æ–ø–æ–ª–∏—è' —Å—Ç–æ–∏—Ç 2500 —Ä—É–±–ª–µ–π.\", metadata={\"id\": \"prod3\"}),\n",
    "    Document(page_content=\"–î–æ—Å—Ç–∞–≤–∫–∞ –æ—Å—É—â–µ—Å—Ç–≤–ª—è–µ—Ç—Å—è –±–µ—Å–ø–ª–∞—Ç–Ω–æ –ø—Ä–∏ –∑–∞–∫–∞–∑–µ –æ—Ç 3000 —Ä—É–±–ª–µ–π. –°—Ä–æ–∫ –¥–æ—Å—Ç–∞–≤–∫–∏ 2-3 –¥–Ω—è.\", metadata={\"id\": \"rule1\"}),\n",
    "    Document(page_content=\"–í–æ–∑–≤—Ä–∞—Ç —Ç–æ–≤–∞—Ä–∞ –≤–æ–∑–º–æ–∂–µ–Ω –≤ —Ç–µ—á–µ–Ω–∏–µ 14 –¥–Ω–µ–π –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ —É–ø–∞–∫–æ–≤–∫–∏.\", metadata={\"id\": \"rule2\"})\n",
    "]\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(documents)\n",
    "vectorstore = FAISS.from_documents(splits, embedding_function)\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 2})\n",
    "\n",
    "\n",
    "# --- 3. –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã ---\n",
    "class CatalogSearchTool(BaseTool_functional):\n",
    "    \"\"\"–ü–æ–∏—Å–∫ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ç–æ–≤–∞—Ä–∞—Ö –∏ –ø—Ä–∞–≤–∏–ª–∞—Ö –º–∞–≥–∞–∑–∏–Ω–∞.\"\"\"\n",
    "    tool_name: ClassVar[str] = \"search_catalog\"\n",
    "    description: ClassVar[str] = \"–ò—Å–ø–æ–ª—å–∑—É–π –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ü–µ–Ω, –æ–ø–∏—Å–∞–Ω–∏–π —Ç–æ–≤–∞—Ä–æ–≤ –∏ —É—Å–ª–æ–≤–∏–π –¥–æ—Å—Ç–∞–≤–∫–∏/–≤–æ–∑–≤—Ä–∞—Ç–∞.\"\n",
    "    query: str = Field(..., description=\"–ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å (–Ω–∞–ø—Ä–∏–º–µ—Ä: '—Ü–µ–Ω–∞ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä–∞' –∏–ª–∏ '—É—Å–ª–æ–≤–∏—è –¥–æ—Å—Ç–∞–≤–∫–∏')\")\n",
    "\n",
    "    async def __call__(self, context: ResearchContext) -> str:\n",
    "        print(f\"   [DEBUG] –ü–æ–∏—Å–∫ –≤ –∫–∞—Ç–∞–ª–æ–≥–µ: {self.query}\")\n",
    "        results = retriever.invoke(self.query)\n",
    "        if results:\n",
    "            found_info = \"\\n\".join([f\"- {doc.page_content}\" for doc in results])\n",
    "            return json.dumps(f\"–ù–∞–π–¥–µ–Ω–æ –≤ –±–∞–∑–µ:\\n{found_info}\", ensure_ascii=False)\n",
    "        return json.dumps(\"–í –∫–∞—Ç–∞–ª–æ–≥–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.\", ensure_ascii=False)\n",
    "\n",
    "class OrderCreationTool(BaseTool_functional):\n",
    "    \"\"\"–û—Ñ–æ—Ä–º–ª–µ–Ω–∏–µ –∑–∞–∫–∞–∑–∞ –Ω–∞ –∏–≥—Ä—É—à–∫–∏.\"\"\"\n",
    "    tool_name: ClassVar[str] = \"create_order\"\n",
    "    description: ClassVar[str] = \"–°–æ–∑–¥–∞–Ω–∏–µ –∑–∞–∫–∞–∑–∞. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –Ω–æ–º–µ—Ä –∑–∞–∫–∞–∑–∞.\"\n",
    "    items: str = Field(..., description=\"–°–ø–∏—Å–æ–∫ —Ç–æ–≤–∞—Ä–æ–≤ –∏ –∏—Ö –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ\")\n",
    "    customer_info: str = Field(..., description=\"–ò–º—è –∏ –∫–æ–Ω—Ç–∞–∫—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –ø–æ–∫—É–ø–∞—Ç–µ–ª—è\")\n",
    "\n",
    "    async def __call__(self, context: ResearchContext) -> str:\n",
    "        print(f\"   [DEBUG] –°–æ–∑–¥–∞–Ω–∏–µ –∑–∞–∫–∞–∑–∞: {self.items} –¥–ª—è {self.customer_info}\")\n",
    "        return json.dumps({\"status\": \"success\", \"order_id\": \"ORD-999\", \"message\": \"Order created successfully\"}, ensure_ascii=False)\n",
    "\n",
    "class OrderStatusTool(BaseTool_functional):\n",
    "    \"\"\"–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å–∞ –∑–∞–∫–∞–∑–∞ –ø–æ –Ω–æ–º–µ—Ä—É.\"\"\"\n",
    "    tool_name: ClassVar[str] = \"check_order_status\"\n",
    "    description: ClassVar[str] = \"–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å–∞ –∑–∞–∫–∞–∑–∞ –ø–æ ID (–Ω–∞–ø—Ä–∏–º–µ—Ä, ORD-999).\"\n",
    "    order_id: str = Field(..., description=\"–ù–æ–º–µ—Ä –∑–∞–∫–∞–∑–∞\")\n",
    "\n",
    "    async def __call__(self, context: ResearchContext) -> str:\n",
    "        print(f\"   [DEBUG] –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å–∞ –∑–∞–∫–∞–∑–∞: {self.order_id}\")\n",
    "        if self.order_id == \"ORD-999\":\n",
    "            return json.dumps(\"–°—Ç–∞—Ç—É—Å: –ü–µ—Ä–µ–¥–∞–Ω –≤ –∫—É—Ä—å–µ—Ä—Å–∫—É—é —Å–ª—É–∂–±—É. –û–∂–∏–¥–∞–π—Ç–µ –¥–æ—Å—Ç–∞–≤–∫—É –∑–∞–≤—Ç—Ä–∞.\", ensure_ascii=False)\n",
    "        return json.dumps(\"–ó–∞–∫–∞–∑ —Å —Ç–∞–∫–∏–º –Ω–æ–º–µ—Ä–æ–º –Ω–µ –Ω–∞–π–¥–µ–Ω.\", ensure_ascii=False)\n",
    "\n",
    "\n",
    "# --- 4. –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ê–≥–µ–Ω—Ç–∞ ---\n",
    "http_client = httpx.AsyncClient(verify=False)\n",
    "\n",
    "llm_client = AsyncOpenAI(\n",
    "    api_key=ACCESS_TOKEN,\n",
    "    base_url=giga_settings.base_url,\n",
    "    http_client=http_client\n",
    ")\n",
    "\n",
    "llm_config = LLMConfig(\n",
    "    api_key=ACCESS_TOKEN,\n",
    "    base_url=giga_settings.base_url,\n",
    "    model=giga_settings.main_model,\n",
    "    temperature=giga_settings.temperature,\n",
    ")\n",
    "\n",
    "prompts_config = PromptsConfig(\n",
    "    system_prompt_str=(\n",
    "        \"–¢—ã –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç –º–∞–≥–∞–∑–∏–Ω–∞ –∏–≥—Ä—É—à–µ–∫ '–î–µ—Ç—Å–∫–∏–π –ú–∏—Ä'. –û—Ç–≤–µ—á–∞–µ—à—å –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –æ —Ç–æ–≤–∞—Ä–∞—Ö –∏ –ø–æ–º–æ–≥–∞–µ—à—å —Å –∑–∞–∫–∞–∑–∞–º–∏.\"\n",
    "        \"–°–ø–∏—Å–æ–∫ —Ç–≤–æ–∏—Ö –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ = [CatalogSearchTool, OrderCreationTool, OrderStatusTool, FinalAnswerTool]\"\n",
    "        \"–ö–æ–≥–¥–∞ –æ—Ç–≤–µ—Ç –≥–æ—Ç–æ–≤ - –≤—ã–∑–æ–≤–∏ FinalAnswerTool.\"\n",
    "        \"–ü–†–ê–í–ò–õ–ê: \"\n",
    "        \"0. –ë—É–¥—å –≤–µ–∂–ª–∏–≤ –∏ –¥—Ä—É–∂–µ–ª—é–±–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–π —ç–º–æ–¥–∑–∏ (üß∏, üöó).\"\n",
    "        \"1. –°–Ω–∞—á–∞–ª–∞ –∏—â–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ –∫–∞—Ç–∞–ª–æ–≥–µ (CatalogSearchTool), –Ω–µ –≤—ã–¥—É–º—ã–≤–∞–π —Ü–µ–Ω—ã.\"\n",
    "        \"2. –ï—Å–ª–∏ –∫–ª–∏–µ–Ω—Ç —Ö–æ—á–µ—Ç –∫—É–ø–∏—Ç—å —Ç–æ–≤–∞—Ä: \"\n",
    "        \" 2.1) –æ—Ñ–æ—Ä–º–∏ –∑–∞–∫–∞–∑ (OrderCreationTool), \"\n",
    "        \" 2.2) –ø–æ—Ç–æ–º –ø—Ä–æ–≤–µ—Ä—å —á—Ç–æ –µ–≥–æ —Å—Ç–∞—Ç—É—Å —É–∂–µ –æ—Ç–æ–±—Ä–∞–∑–∏–ª—Å—è –≤ —Å–∏—Å—Ç–µ–º–µ (–í–ê–ñ–ù–û!) (OrderStatusTool)\"\n",
    "        \" 2.3) –ø–æ—Ç–æ–º —Å–∫–∞–∂–∏ –Ω–æ–º–µ—Ä –∑–∞–∫–∞–∑–∞ –∏ —Å—Ä–æ–∫ –¥–æ—Å—Ç–∞–≤–∫–∏.\"\n",
    "        \"3. –ï—Å–ª–∏ —Å–ø—Ä–∞—à–∏–≤–∞—é—Ç –ø—Ä–æ —É—Å–ª–æ–≤–∏—è –¥–æ—Å—Ç–∞–≤–∫–∏, —Ç–æ–∂–µ —Å–º–æ—Ç—Ä–∏ –≤ CatalogSearchTool.\"\n",
    "    ),\n",
    "    initial_user_request_str=None,\n",
    "    clarification_response_str=\"–£—Ç–æ—á–Ω–∏—Ç–µ, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞, –∫–∞–∫—É—é –∏–º–µ–Ω–Ω–æ –∏–≥—Ä—É—à–∫—É –≤—ã –∏—â–µ—Ç–µ?\"\n",
    ")\n",
    "\n",
    "execution_config = ExecutionConfig(\n",
    "    max_iterations=5,\n",
    "    max_searches=0\n",
    ")\n",
    "\n",
    "tools_list = [\n",
    "    CatalogSearchTool, OrderCreationTool, OrderStatusTool, \n",
    "    # ClarificationTool_functional, \n",
    "    # GeneratePlanTool_functional, \n",
    "    # AdaptPlanTool_functional, \n",
    "    # ReasoningTool_functional, \n",
    "    FinalAnswerTool_functional\n",
    "]\n",
    "\n",
    "\n",
    "# --- 5. –ó–∞–ø—É—Å–∫ ---\n",
    "async def run_agent_demo(user_input: str):\n",
    "    print(f\"\\n>>> –ü–û–ö–£–ü–ê–¢–ï–õ–¨: {user_input}\")\n",
    "    \n",
    "    agent = ToolCallingAgent(\n",
    "        task=user_input,\n",
    "        openai_client=llm_client,\n",
    "        llm_config=llm_config,\n",
    "        prompts_config=prompts_config,\n",
    "        execution_config=execution_config,\n",
    "        toolkit=tools_list,\n",
    "    )\n",
    "    \n",
    "    await agent.execute()\n",
    "    \n",
    "    print(\"AGENTS LOG:\")\n",
    "    for msg in agent.conversation:\n",
    "        role = msg.get(\"role\")\n",
    "        content = msg.get(\"content\")\n",
    "        if role == \"assistant\" and content:\n",
    "            print(f\"[{role}]: {content}\")\n",
    "        elif role == \"tool\":\n",
    "            print(f\"[{role}]: {content}\")\n",
    "\n",
    "# –ó–∞–ø—É—Å–∫\n",
    "if __name__ == \"__main__\":\n",
    "    # –°—Ü–µ–Ω–∞—Ä–∏–π 1: –í–æ–ø—Ä–æ—Å –ø–æ –∫–∞—Ç–∞–ª–æ–≥—É\n",
    "    await run_agent_demo(\"–°–∫–æ–ª—å–∫–æ —Å—Ç–æ–∏—Ç –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä –∑–≤–µ–∑–¥–Ω—ã–π –∫—Ä–µ–π—Å–µ—Ä –∏ –µ—Å—Ç—å –ª–∏ –±–µ—Å–ø–ª–∞—Ç–Ω–∞—è –¥–æ—Å—Ç–∞–≤–∫–∞?\")\n",
    "    \n",
    "    # –°—Ü–µ–Ω–∞—Ä–∏–π 2: –ü–æ–∫—É–ø–∫–∞\n",
    "    await run_agent_demo(\"–•–æ—á—É –∫—É–ø–∏—Ç—å –ø–ª—é—à–µ–≤–æ–≥–æ –º–µ–¥–≤–µ–¥—è. –ú–µ–Ω—è –∑–æ–≤—É—Ç –°–∞—à–∞, —Ç–µ–ª–µ—Ñ–æ–Ω 89990000000. –û—Ñ–æ—Ä–º–∏—Ç–µ –∑–∞–∫–∞–∑.\")\n",
    "    \n",
    "    await run_agent_demo(\"–ü—Ä–∏–≤–µ—Ç, —Å–Ω–æ–≤–∞ –°–∞—à–∞. –ö–∞–∫–æ–π —Å—Ç–∞—Ç—É—Å —É –∑–∞–∫–∞–∑–∞ ORD-999?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4c5a6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51588eb-1e1e-4f34-b9c2-5c7e6d34a301",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
